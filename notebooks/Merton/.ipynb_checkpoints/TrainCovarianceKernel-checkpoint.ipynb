{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "fe2f12a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.optim import Adam\n",
    "\n",
    "import os\n",
    "import json\n",
    "import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "from torch.distributions import Normal, Poisson, MultivariateNormal\n",
    "from gpytorch.kernels import RBFKernel, ScaleKernel\n",
    "from torch import nn\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from deep_fields.models.utils.basic_setups import create_dir_and_writer\n",
    "\n",
    "from deep_fields.models.gaussian_processes.gaussian_processes import multivariate_normal, white_noise_kernel\n",
    "\n",
    "from deep_fields.models.random_fields.blocks_utils_torch import calculate_determinant_and_inverse_covariance_history_torch\n",
    "from deep_fields.models.random_fields.blocks_utils_torch import obtain_location_index_to_realization, obtain_blocks\n",
    "from deep_fields.models.random_fields.blocks_utils_torch import log_probability_from_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "aa98e1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_dimension = 2\n",
    "prior_locations_mean =  0.\n",
    "prior_locations_std = 6.69\n",
    "number_of_realizations = 100\n",
    "birth_intensity = 2.\n",
    "kernel_sigma = 10.\n",
    "kernel_lenght_scales = [1., 2.]\n",
    "\n",
    "locations_prior = Normal(torch.full((locations_dimension,), prior_locations_mean),\n",
    "                         torch.full((locations_dimension,), prior_locations_std))\n",
    "\n",
    "# Births\n",
    "birth_distribution = Poisson(birth_intensity)\n",
    "birth_numbers = birth_distribution.sample((number_of_realizations,)).long()\n",
    "assets_in_the_market = birth_numbers.cumsum(dim=0)\n",
    "total_assets_in_history = assets_in_the_market[-1]\n",
    "\n",
    "# Locations\n",
    "locations_history = locations_prior.sample(sample_shape=(total_assets_in_history,))\n",
    "    \n",
    "def define_kernel(kernel_sigma, kernel_lenght_scales):\n",
    "    kernel = ScaleKernel(RBFKernel(ard_num_dims=locations_dimension, requires_grad=True),\n",
    "                         requires_grad=True) + white_noise_kernel()\n",
    "\n",
    "    kernel_hypers = {\"raw_outputscale\": torch.tensor(kernel_sigma),\n",
    "                     \"base_kernel.raw_lengthscale\": torch.tensor(kernel_lenght_scales)}\n",
    "\n",
    "    kernel.kernels[0].initialize(**kernel_hypers)\n",
    "    kernel_eval = lambda locations: kernel(locations, locations).evaluate().type(torch.float64)\n",
    "    \n",
    "    return kernel, kernel_eval\n",
    "    \n",
    "def define_covariance_matrix_from_kernel(number_of_realizations,birth_intensity,kernel_sigma,kernel_lenght_scales):    \n",
    "    number_of_realizations = number_of_realizations\n",
    "\n",
    "    # Kernel\n",
    "    kernel, kernel_eval = define_kernel(kernel_sigma,kernel_lenght_scales)\n",
    "    covariance_diffusion_history = kernel_eval(locations_history)\n",
    "    \n",
    "    return covariance_diffusion_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "728ae93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = torch.ones(total_assets_in_history).type(torch.float64)*0.01\n",
    "covariance_matrix = define_covariance_matrix_from_kernel(number_of_realizations,birth_intensity,kernel_sigma,kernel_lenght_scales)\n",
    "# generate data\n",
    "distribution = MultivariateNormal(mu,covariance_matrix)\n",
    "sample = distribution.sample(sample_shape=(number_of_realizations,))\n",
    "for i,current_number_of_assets in enumerate(assets_in_the_market):\n",
    "    sample[i,current_number_of_assets:] = torch.zeros_like(sample[i,current_number_of_assets:])\n",
    "log_returns = sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9f4c35d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "determinants_history, inverse_covariance_history = calculate_determinant_and_inverse_covariance_history_torch(\n",
    "    assets_in_the_market, covariance_matrix, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4822321e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real 2.276692252639558e-08 Estimated 2.276679379085766e-08\n",
      "Last Element of Diagonal 1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "print(\"Real {0} Estimated {1}\".format(torch.det(covariance_matrix),determinants_history[-1]))\n",
    "print(\"Last Element of Diagonal {0}\".format(torch.matmul(covariance_matrix,inverse_covariance_history[-1])[-1,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "db501bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MertonBirthKernel(nn.Module):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        nn.Module.__init__(self)\n",
    "        self.locations_dimension = kwargs.get(\"locations_dimension\")\n",
    "        self.define_deep_parameters()\n",
    "        \n",
    "    def define_kernel(self):\n",
    "        kernel = ScaleKernel(RBFKernel(ard_num_dims=self.locations_dimension, requires_grad=True),\n",
    "                             requires_grad=True) + white_noise_kernel()\n",
    "\n",
    "        kernel_hypers = {\"raw_outputscale\": torch.tensor(self.kernel_sigma),\n",
    "                         \"base_kernel.raw_lengthscale\": torch.tensor(self.kernel_lenght_scales)}\n",
    "\n",
    "        kernel.kernels[0].initialize(**kernel_hypers)\n",
    "        kernel_eval = lambda locations: kernel(locations, locations).evaluate().type(torch.float64)\n",
    "\n",
    "        return kernel, kernel_eval\n",
    "\n",
    "    def forward(self, locations_history):\n",
    "        kernel, kernel_eval = define_kernel(kernel_sigma,kernel_lenght_scales)\n",
    "        covariance_diffusion_history = kernel_eval(locations_history)\n",
    "        return covariance_diffusion_history\n",
    "\n",
    "    def define_deep_parameters(self):\n",
    "        self.kernel_sigma = nn.Parameter(torch.Tensor([1.]))\n",
    "        self.kernel_lenght_scales = nn.Parameter(torch.Tensor([20.,30.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1ade942a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/100 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.DoubleTensor []], which is output 0 of SelectBackward, is at version 101; expected version 99 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-134-651cc0c0a9d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m         assets_in_the_market, covariance_matrix, False)\n\u001b[0;32m      8\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlog_probability_from_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0massets_in_the_market\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdeterminants_history\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minverse_covariance_history\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\cesar\\anaconda3\\envs\\deep_fields\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 245\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\cesar\\anaconda3\\envs\\deep_fields\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.DoubleTensor []], which is output 0 of SelectBackward, is at version 101; expected version 99 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True)."
     ]
    }
   ],
   "source": [
    "number_of_epochs = 100\n",
    "mbk = MertonBirthKernel(locations_dimension=locations_dimension)\n",
    "optimizer = Adam(mbk.parameters(), lr=0.001)\n",
    "for i in tqdm.tqdm(range(number_of_epochs)):\n",
    "    covariance_matrix = mbk(locations_history)\n",
    "    determinants_history, inverse_covariance_history = calculate_determinant_and_inverse_covariance_history_torch(\n",
    "        assets_in_the_market, covariance_matrix, False)\n",
    "    loss = log_probability_from_blocks(sample,mu,assets_in_the_market,determinants_history,inverse_covariance_history).sum()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82d2c59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
